{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from bs4 import BeautifulSoup\n",
    "import unidecode as unidecode\n",
    "import gensim.downloader as api\n",
    "import regex as re\n",
    "from textblob import TextBlob\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mature intelligent and highly charged melodram...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://video.google.com/videoplay?docid=211772...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Title: Opera (1987) Director: Dario Argento Ca...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I think a lot of people just wrote this off as...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is a story of two dogs and a cat looking ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review label\n",
       "0  mature intelligent and highly charged melodram...   pos\n",
       "1  http://video.google.com/videoplay?docid=211772...   pos\n",
       "2  Title: Opera (1987) Director: Dario Argento Ca...   pos\n",
       "3  I think a lot of people just wrote this off as...   pos\n",
       "4  This is a story of two dogs and a cat looking ...   pos"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://video.google.com/videoplay?docid=211772166650071408&hl=en Distribution was tried.<br /><br />We opted for mass appeal.<br /><br />We want the best possible viewing range so, we forgo profit and continue our manual labor jobs gladly to entertain you for working yours.<br /><br />View Texas tale, please write about it... If you like it or not, if you like Alex or not, if you like Stuie, Texas or Texas tale... Just write about it.<br /><br />Your opinion rules.\n"
     ]
    }
   ],
   "source": [
    "print(data[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text) :\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    text = url_pattern.sub(r'', text)\n",
    "    text = unidecode.unidecode(text)\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    stripped_text = soup.get_text(separator = ' ')\n",
    "    return stripped_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "xraw = list(data[:, 0].reshape((-1, )))\n",
    "Y = data[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000,)\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for text in xraw :\n",
    "    X.append(text)\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000,),\n",
       " \"mature intelligent and highly charged melodrama unbelivebly filmed in China in 1948. wei wei's stunning performance as the catylast in a love triangle is simply stunning if you have the oppurunity to see this magnificent film take it\")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "swords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'theirs', 'whom', 'nor', 'down', 'does', 'of', 'yourself', 'haven', 'o', 'this', 'couldn', 'was', 'below', 'being', 'with', 'through', \"haven't\", 'themselves', 'here', 're', 'our', 'be', 'under', 'you', 'that', 'are', 'into', 'then', 'too', 'wouldn', \"couldn't\", \"should've\", 'did', 'shouldn', \"needn't\", 'only', 'when', 'hasn', 'most', \"mustn't\", 'in', 'd', 's', 'other', 'on', 'again', 'out', \"aren't\", 'few', 'further', 'same', 'more', 'a', 'very', 'yourselves', 'herself', 'over', 'how', 'it', 'their', 'own', 'should', 'll', 've', \"shouldn't\", \"wasn't\", 'to', 'he', 'between', 'yours', 'or', 'above', 'weren', 'because', \"she's\", 'ours', 'has', 'isn', \"you'll\", \"hasn't\", 'her', 'during', 'after', 'while', \"weren't\", 'himself', 'its', 'your', 'his', 'y', \"wouldn't\", 'is', 'just', 'all', \"you'd\", \"that'll\", 'ain', 'm', 'who', 'the', 'doesn', 'by', 'there', \"don't\", 'having', \"didn't\", 'not', \"doesn't\", \"it's\", 'about', 'didn', \"you've\", 'before', 'wasn', 'needn', 'ourselves', 'but', 'if', 'up', 'off', 'than', 'once', 'my', 'do', 'both', \"won't\", 'hadn', 'him', 'been', 'mustn', 'we', 'such', 't', 'she', 'doing', 'so', 'can', 'until', 'now', 'don', 'which', \"mightn't\", 'any', 'some', 'each', 'itself', \"isn't\", 'am', 'against', 'at', 'no', 'where', 'these', 'ma', 'and', 'me', 'had', 'them', \"hadn't\", 'have', \"shan't\", 'they', 'will', 'were', \"you're\", 'from', 'shan', 'won', 'mightn', 'why', 'hers', 'as', 'aren', 'for', 'what', 'those', 'myself', 'an', 'i'}\n"
     ]
    }
   ],
   "source": [
    "print(swords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(\"[a-zA-Z']+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text, stopwords) :\n",
    "    useful_words = [w for w in text if w not in stopwords]\n",
    "    return useful_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myTokenizer(document) :\n",
    "    words = tokenizer.tokenize(document)\n",
    "    words = remove_stopwords(words, swords)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(lowercase = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vectorized = []\n",
    "tokens = []\n",
    "for i in X :\n",
    "    words = myTokenizer(i)\n",
    "    tokens += set(words)\n",
    "    x_vectorized.append(np.array(words))\n",
    "tokens = set(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mature' 'intelligent' 'highly' 'charged' 'melodrama' 'unbelivebly'\n",
      " 'filmed' 'China' 'wei' \"wei's\" 'stunning' 'performance' 'catylast' 'love'\n",
      " 'triangle' 'simply' 'stunning' 'oppurunity' 'see' 'magnificent' 'film'\n",
      " 'take']\n"
     ]
    }
   ],
   "source": [
    "print(x_vectorized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = Y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypos = 0\n",
    "yneg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "posmap = {}\n",
    "negmap = {}\n",
    "for i in tokens :\n",
    "    posmap[i] = 0\n",
    "    negmap[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_total) :\n",
    "    if Y[i] == 'pos' :\n",
    "        ypos += 1\n",
    "        for x in x_vectorized[i] :\n",
    "            posmap[x] += 1\n",
    "    else :\n",
    "        yneg += 1\n",
    "        for x in x_vectorized[i] :\n",
    "            negmap[x] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20011, 19989)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypos, yneg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "poswords = sum([1 for i in posmap.values() if i > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "negwords = sum([1 for i in negmap.values() if i > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalposwords = sum(posmap.values())\n",
    "totalnegwords = sum(negmap.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96813, 92185)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poswords, negwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134388"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_prob_pos = ypos / n_total\n",
    "prior_prob_neg = yneg / n_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.500275, 0.499725)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior_prob_pos, prior_prob_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134388"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(word, cls) :\n",
    "    if word not in tokens :\n",
    "        return 1/vocab_size\n",
    "    if cls == 'pos' :\n",
    "        return (posmap[word] + 1) / (totalposwords + vocab_size)\n",
    "    else :\n",
    "        return (negmap[word] + 1) / (totalnegwords + vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(document) :\n",
    "    text = preprocess_text(document)\n",
    "    words = myTokenizer(text)\n",
    "    text_vocab = {}\n",
    "    probpos = 1\n",
    "    probneg = 1\n",
    "    for i in set(words) :\n",
    "        probpos *= likelihood(i, 'pos')\n",
    "        probneg *= likelihood(i, 'neg')\n",
    "    probpos *= prior_prob_pos\n",
    "    probneg *= prior_prob_neg\n",
    "    if probpos >= probneg :\n",
    "        return 'pos'\n",
    "    else :\n",
    "        return 'neg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = pd.read_csv('Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Remember those old kung fu movies we used to w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This movie is another one on my List of Movies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How in the world does a thing like this get in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Queen of the Damned\" is one of the best vampi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Caprica episode (S01E01) is well done as a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0  Remember those old kung fu movies we used to w...\n",
       "1  This movie is another one on my List of Movies...\n",
       "2  How in the world does a thing like this get in...\n",
       "3  \"Queen of the Damned\" is one of the best vampi...\n",
       "4  The Caprica episode (S01E01) is well done as a..."
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "xtest = dftest.values.reshape((-1, ))\n",
    "print(xtest.shape)\n",
    "print(type(xtest[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in range(xtest.shape[0]) :\n",
    "    predictions.append(np.array([i, predict(xtest[i])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['0', 'pos'], dtype='<U21'),\n",
       " array(['1', 'pos'], dtype='<U21'),\n",
       " array(['2', 'pos'], dtype='<U21'),\n",
       " array(['3', 'pos'], dtype='<U21'),\n",
       " array(['4', 'pos'], dtype='<U21'),\n",
       " array(['5', 'neg'], dtype='<U21'),\n",
       " array(['6', 'pos'], dtype='<U21'),\n",
       " array(['7', 'pos'], dtype='<U21'),\n",
       " array(['8', 'pos'], dtype='<U21'),\n",
       " array(['9', 'pos'], dtype='<U21')]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest = np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = pd.DataFrame(ytest, columns = ['Id', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans.to_csv('ans.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
